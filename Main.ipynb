{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------STARTING POINT---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ON_SAGEMAKER_NOTEBOOK = True\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "if ON_SAGEMAKER_NOTEBOOK:\n",
    "    role = sagemaker.get_execution_role()\n",
    "else:\n",
    "    role = \"[YOUR ROLE]\"\n",
    "\n",
    "\n",
    "bucket = \"sagemaker-eu-west-2-239890342195\"\n",
    "key = \"image-classification-full-training\"\n",
    "key_output = \"output\"                   # Path from the bucket's root to the dataset\n",
    "train_instance_type='ml.m5.large'      # The type of EC2 instance which will be used for training\n",
    "deploy_instance_type='ml.m5.large'     # The type of EC2 instance which will be used for deployment\n",
    "hyperparameters={\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"decay\": 1e-6\n",
    "}\n",
    "\n",
    "train_input_path = \"s3://{}/{}/train/\".format(bucket, key)\n",
    "validation_input_path = \"s3://{}/{}/validation/\".format(bucket, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_use_spot_instances=True\n",
    "train_max_run=3600\n",
    "train_max_wait = 3600 if train_use_spot_instances else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.1.0 is the latest version of tensorflow that supports Python 2. Newer versions of tensorflow will only be available for Python 3.Please set the argument \"py_version='py3'\" to use the Python 3 tensorflow image.\n",
      "Legacy mode is deprecated in versions 1.13 and higher. Using script mode instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "2020-06-09 15:47:23 Starting - Starting the training job...\n",
      "2020-06-09 15:47:25 Starting - Launching requested ML instances......\n",
      "2020-06-09 15:48:28 Starting - Preparing the instances for training......\n",
      "2020-06-09 15:49:46 Downloading - Downloading input data......\n",
      "2020-06-09 15:50:52 Training - Training image download completed. Training in progress..\u001b[34mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mFound 5216 images belonging to 2 classes.\u001b[0m\n",
      "\u001b[34mFound 16 images belonging to 2 classes.\u001b[0m\n",
      "\u001b[34mWARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[34mW0609 15:50:57.286032 140150207923968 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0609 15:50:57.306328 140150207923968 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0609 15:50:57.316343 140150207923968 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0609 15:50:57.339193 140150207923968 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0609 15:50:57.339358 140150207923968 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2020-06-09 15:50:57.474277: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[34mW0609 15:50:57.500657 140150207923968 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0609 15:50:57.552290 140150207923968 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\u001b[0m\n",
      "\u001b[34mDownloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\n",
      "   16384/94653016 [..............................] - ETA: 0s\n",
      "   24576/94653016 [..............................] - ETA: 4:50\n",
      "   57344/94653016 [..............................] - ETA: 4:09\n",
      "  122880/94653016 [..............................] - ETA: 2:54\u001b[0m\n",
      "\u001b[34m  262144/94653016 [..............................] - ETA: 1:48\n",
      "  573440/94653016 [..............................] - ETA: 1:02\n",
      " 1171456/94653016 [..............................] - ETA: 36s \n",
      " 2351104/94653016 [..............................] - ETA: 20s\n",
      " 3923968/94653016 [>.............................] - ETA: 14s\n",
      " 5496832/94653016 [>.............................] - ETA: 11s\n",
      " 7069696/94653016 [=>............................] - ETA: 9s \n",
      " 8658944/94653016 [=>............................] - ETA: 8s\u001b[0m\n",
      "\u001b[34m10231808/94653016 [==>...........................] - ETA: 7s\u001b[0m\n",
      "\u001b[34m11804672/94653016 [==>...........................] - ETA: 6s\u001b[0m\n",
      "\u001b[34m13377536/94653016 [===>..........................] - ETA: 6s\u001b[0m\n",
      "\u001b[34m14950400/94653016 [===>..........................] - ETA: 6s\u001b[0m\n",
      "\u001b[34m16523264/94653016 [====>.........................] - ETA: 5s\u001b[0m\n",
      "\u001b[34m18096128/94653016 [====>.........................] - ETA: 5s\u001b[0m\n",
      "\u001b[34m19668992/94653016 [=====>........................] - ETA: 5s\u001b[0m\n",
      "\u001b[34m21241856/94653016 [=====>........................] - ETA: 4s\u001b[0m\n",
      "\u001b[34m22831104/94653016 [======>.......................] - ETA: 4s\u001b[0m\n",
      "\u001b[34m24403968/94653016 [======>.......................] - ETA: 4s\u001b[0m\n",
      "\u001b[34m25976832/94653016 [=======>......................] - ETA: 4s\u001b[0m\n",
      "\u001b[34m27549696/94653016 [=======>......................] - ETA: 4s\u001b[0m\n",
      "\u001b[34m29122560/94653016 [========>.....................] - ETA: 4s\u001b[0m\n",
      "\u001b[34m30695424/94653016 [========>.....................] - ETA: 3s\u001b[0m\n",
      "\u001b[34m32268288/94653016 [=========>....................] - ETA: 3s\u001b[0m\n",
      "\u001b[34m33841152/94653016 [=========>....................] - ETA: 3s\u001b[0m\n",
      "\u001b[34m35430400/94653016 [==========>...................] - ETA: 3s\u001b[0m\n",
      "\u001b[34m37003264/94653016 [==========>...................] - ETA: 3s\u001b[0m\n",
      "\u001b[34m38576128/94653016 [===========>..................] - ETA: 3s\u001b[0m\n",
      "\u001b[34m40148992/94653016 [===========>..................] - ETA: 3s\u001b[0m\n",
      "\u001b[34m41721856/94653016 [============>.................] - ETA: 3s\u001b[0m\n",
      "\u001b[34m43294720/94653016 [============>.................] - ETA: 2s\u001b[0m\n",
      "\u001b[34m44867584/94653016 [=============>................] - ETA: 2s\u001b[0m\n",
      "\u001b[34m46440448/94653016 [=============>................] - ETA: 2s\u001b[0m\n",
      "\u001b[34m48029696/94653016 [==============>...............] - ETA: 2s\u001b[0m\n",
      "\u001b[34m49602560/94653016 [==============>...............] - ETA: 2s\u001b[0m\n",
      "\u001b[34m51175424/94653016 [===============>..............] - ETA: 2s\u001b[0m\n",
      "\u001b[34m52748288/94653016 [===============>..............] - ETA: 2s\u001b[0m\n",
      "\u001b[34m54321152/94653016 [================>.............] - ETA: 2s\u001b[0m\n",
      "\u001b[34m55894016/94653016 [================>.............] - ETA: 2s\u001b[0m\n",
      "\u001b[34m57466880/94653016 [=================>............] - ETA: 2s\u001b[0m\n",
      "\u001b[34m59039744/94653016 [=================>............] - ETA: 1s\u001b[0m\n",
      "\u001b[34m60628992/94653016 [==================>...........] - ETA: 1s\u001b[0m\n",
      "\u001b[34m62201856/94653016 [==================>...........] - ETA: 1s\u001b[0m\n",
      "\u001b[34m63774720/94653016 [===================>..........] - ETA: 1s\u001b[0m\n",
      "\u001b[34m65347584/94653016 [===================>..........] - ETA: 1s\u001b[0m\n",
      "\u001b[34m66920448/94653016 [====================>.........] - ETA: 1s\u001b[0m\n",
      "\u001b[34m68493312/94653016 [====================>.........] - ETA: 1s\u001b[0m\n",
      "\u001b[34m70066176/94653016 [=====================>........] - ETA: 1s\u001b[0m\n",
      "\u001b[34m71639040/94653016 [=====================>........] - ETA: 1s\u001b[0m\n",
      "\u001b[34m73211904/94653016 [======================>.......] - ETA: 1s\u001b[0m\n",
      "\u001b[34m74801152/94653016 [======================>.......] - ETA: 1s\u001b[0m\n",
      "\u001b[34m76374016/94653016 [=======================>......] - ETA: 0s\u001b[0m\n",
      "\u001b[34m77946880/94653016 [=======================>......] - ETA: 0s\u001b[0m\n",
      "\u001b[34m79519744/94653016 [========================>.....] - ETA: 0s\u001b[0m\n",
      "\u001b[34m81092608/94653016 [========================>.....] - ETA: 0s\u001b[0m\n",
      "\u001b[34m82665472/94653016 [=========================>....] - ETA: 0s\u001b[0m\n",
      "\u001b[34m84238336/94653016 [=========================>....] - ETA: 0s\u001b[0m\n",
      "\u001b[34m85827584/94653016 [==========================>...] - ETA: 0s\u001b[0m\n",
      "\u001b[34m87400448/94653016 [==========================>...] - ETA: 0s\u001b[0m\n",
      "\u001b[34m88973312/94653016 [===========================>..] - ETA: 0s\u001b[0m\n",
      "\u001b[34m90546176/94653016 [===========================>..] - ETA: 0s\u001b[0m\n",
      "\u001b[34m92119040/94653016 [============================>.] - ETA: 0s\u001b[0m\n",
      "\u001b[34m93691904/94653016 [============================>.] - ETA: 0s\u001b[0m\n",
      "\u001b[34m94658560/94653016 [==============================] - 5s 0us/step\n",
      "\u001b[0m\n",
      "\u001b[34m94666752/94653016 [==============================] - 5s 0us/step\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                 Output Shape              Param #   \u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34mresnet50 (Model)             (None, 2048)              23587712  \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_1 (Dense)              (None, 2)                 4098      \u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 23,591,810\u001b[0m\n",
      "\u001b[34mTrainable params: 4,098\u001b[0m\n",
      "\u001b[34mNon-trainable params: 23,587,712\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mNone\u001b[0m\n",
      "\u001b[34mW0609 15:51:16.066063 140150207923968 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0609 15:51:16.152668 140150207923968 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34mEpoch 1/5\u001b[0m\n",
      "\u001b[34m 1/53 [..............................] - ETA: 19:47 - loss: 0.9843 - acc: 0.4000\u001b[0m\n",
      "\u001b[34m 2/53 [>.............................] - ETA: 13:06 - loss: 0.8135 - acc: 0.5050\u001b[0m\n",
      "\u001b[34m 3/53 [>.............................] - ETA: 10:31 - loss: 0.7118 - acc: 0.5967\u001b[0m\n",
      "\u001b[34m 4/53 [=>............................] - ETA: 9:08 - loss: 0.7121 - acc: 0.6300 \u001b[0m\n",
      "\u001b[34m 5/53 [=>............................] - ETA: 8:17 - loss: 0.6791 - acc: 0.6620\u001b[0m\n",
      "\u001b[34m 6/53 [==>...........................] - ETA: 7:38 - loss: 0.6639 - acc: 0.6833\u001b[0m\n",
      "\u001b[34m 7/53 [==>...........................] - ETA: 7:10 - loss: 0.6178 - acc: 0.7071\u001b[0m\n",
      "\u001b[34m 8/53 [===>..........................] - ETA: 6:48 - loss: 0.6004 - acc: 0.7125\u001b[0m\n",
      "\u001b[34m 9/53 [====>.........................] - ETA: 6:28 - loss: 0.5750 - acc: 0.7233\u001b[0m\n",
      "\u001b[34m10/53 [====>.........................] - ETA: 6:10 - loss: 0.5535 - acc: 0.7360\u001b[0m\n",
      "\u001b[34m11/53 [=====>........................] - ETA: 5:56 - loss: 0.5360 - acc: 0.7509\u001b[0m\n",
      "\u001b[34m12/53 [=====>........................] - ETA: 5:42 - loss: 0.5188 - acc: 0.7633\u001b[0m\n",
      "\u001b[34m13/53 [======>.......................] - ETA: 5:29 - loss: 0.5008 - acc: 0.7762\u001b[0m\n",
      "\u001b[34m14/53 [======>.......................] - ETA: 5:17 - loss: 0.4871 - acc: 0.7836\u001b[0m\n",
      "\u001b[34m15/53 [=======>......................] - ETA: 5:06 - loss: 0.4734 - acc: 0.7920\u001b[0m\n",
      "\u001b[34m16/53 [========>.....................] - ETA: 4:56 - loss: 0.4598 - acc: 0.8000\u001b[0m\n",
      "\u001b[34m17/53 [========>.....................] - ETA: 4:45 - loss: 0.4482 - acc: 0.8059\u001b[0m\n",
      "\u001b[34m18/53 [=========>....................] - ETA: 4:35 - loss: 0.4360 - acc: 0.8122\u001b[0m\n",
      "\u001b[34m19/53 [=========>....................] - ETA: 4:26 - loss: 0.4280 - acc: 0.8147\u001b[0m\n",
      "\u001b[34m20/53 [==========>...................] - ETA: 4:17 - loss: 0.4170 - acc: 0.8195\u001b[0m\n",
      "\u001b[34m21/53 [==========>...................] - ETA: 4:08 - loss: 0.4050 - acc: 0.8262\u001b[0m\n",
      "\u001b[34m22/53 [===========>..................] - ETA: 3:59 - loss: 0.3969 - acc: 0.8295\u001b[0m\n",
      "\u001b[34m23/53 [============>.................] - ETA: 3:50 - loss: 0.3902 - acc: 0.8335\u001b[0m\n",
      "\u001b[34m24/53 [============>.................] - ETA: 3:41 - loss: 0.3825 - acc: 0.8367\u001b[0m\n",
      "\u001b[34m25/53 [=============>................] - ETA: 3:33 - loss: 0.3760 - acc: 0.8404\u001b[0m\n",
      "\u001b[34m26/53 [=============>................] - ETA: 3:25 - loss: 0.3693 - acc: 0.8438\u001b[0m\n",
      "\u001b[34m27/53 [==============>...............] - ETA: 3:16 - loss: 0.3631 - acc: 0.8470\u001b[0m\n",
      "\u001b[34m28/53 [==============>...............] - ETA: 3:08 - loss: 0.3576 - acc: 0.8504\u001b[0m\n",
      "\u001b[34m29/53 [===============>..............] - ETA: 3:00 - loss: 0.3517 - acc: 0.8538\u001b[0m\n",
      "\u001b[34m30/53 [===============>..............] - ETA: 2:52 - loss: 0.3461 - acc: 0.8557\u001b[0m\n",
      "\u001b[34m31/53 [================>.............] - ETA: 2:44 - loss: 0.3431 - acc: 0.8571\u001b[0m\n",
      "\u001b[34m32/53 [=================>............] - ETA: 2:36 - loss: 0.3383 - acc: 0.8594\u001b[0m\n",
      "\u001b[34m33/53 [=================>............] - ETA: 2:28 - loss: 0.3340 - acc: 0.8609\u001b[0m\n",
      "\u001b[34m34/53 [==================>...........] - ETA: 2:21 - loss: 0.3307 - acc: 0.8624\u001b[0m\n",
      "\u001b[34m35/53 [==================>...........] - ETA: 2:13 - loss: 0.3261 - acc: 0.8649\u001b[0m\n",
      "\u001b[34m36/53 [===================>..........] - ETA: 2:05 - loss: 0.3220 - acc: 0.8672\u001b[0m\n",
      "\u001b[34m37/53 [===================>..........] - ETA: 1:58 - loss: 0.3196 - acc: 0.8684\u001b[0m\n",
      "\u001b[34m38/53 [====================>.........] - ETA: 1:50 - loss: 0.3142 - acc: 0.8705\u001b[0m\n",
      "\u001b[34m39/53 [=====================>........] - ETA: 1:43 - loss: 0.3093 - acc: 0.8723\u001b[0m\n",
      "\u001b[34m40/53 [=====================>........] - ETA: 1:35 - loss: 0.3063 - acc: 0.8738\u001b[0m\n",
      "\u001b[34m41/53 [======================>.......] - ETA: 1:28 - loss: 0.3030 - acc: 0.8756\u001b[0m\n",
      "\u001b[34m42/53 [======================>.......] - ETA: 1:20 - loss: 0.2993 - acc: 0.8771\u001b[0m\n",
      "\u001b[34m43/53 [=======================>......] - ETA: 1:13 - loss: 0.2960 - acc: 0.8784\u001b[0m\n",
      "\u001b[34m44/53 [=======================>......] - ETA: 1:05 - loss: 0.2937 - acc: 0.8789\u001b[0m\n",
      "\u001b[34m45/53 [========================>.....] - ETA: 58s - loss: 0.2897 - acc: 0.8804 \u001b[0m\n",
      "\u001b[34m46/53 [=========================>....] - ETA: 50s - loss: 0.2866 - acc: 0.8815\u001b[0m\n",
      "\u001b[34m47/53 [=========================>....] - ETA: 43s - loss: 0.2837 - acc: 0.8830\u001b[0m\n",
      "\u001b[34m48/53 [==========================>...] - ETA: 36s - loss: 0.2809 - acc: 0.8840\u001b[0m\n",
      "\u001b[34m49/53 [==========================>...] - ETA: 29s - loss: 0.2788 - acc: 0.8845\u001b[0m\n",
      "\u001b[34m50/53 [===========================>..] - ETA: 21s - loss: 0.2768 - acc: 0.8852\u001b[0m\n",
      "\u001b[34m51/53 [===========================>..] - ETA: 14s - loss: 0.2738 - acc: 0.8869\u001b[0m\n",
      "\u001b[34m52/53 [============================>.] - ETA: 7s - loss: 0.2720 - acc: 0.8871 \u001b[0m\n",
      "\u001b[34m53/53 [==============================] - 383s 7s/step - loss: 0.2712 - acc: 0.8881 - val_loss: 2.3232 - val_acc: 0.5000\u001b[0m\n",
      "\u001b[34mEpoch 2/5\u001b[0m\n",
      "\u001b[34m 1/53 [..............................] - ETA: 6:05 - loss: 0.1408 - acc: 0.9500\u001b[0m\n",
      "\u001b[34m 2/53 [>.............................] - ETA: 5:57 - loss: 0.1151 - acc: 0.9650\u001b[0m\n",
      "\u001b[34m 3/53 [>.............................] - ETA: 5:50 - loss: 0.1108 - acc: 0.9600\u001b[0m\n",
      "\u001b[34m 4/53 [=>............................] - ETA: 5:43 - loss: 0.1290 - acc: 0.9425\u001b[0m\n",
      "\u001b[34m 5/53 [=>............................] - ETA: 5:36 - loss: 0.1267 - acc: 0.9480\u001b[0m\n",
      "\u001b[34m 6/53 [==>...........................] - ETA: 5:35 - loss: 0.1229 - acc: 0.9517\u001b[0m\n",
      "\u001b[34m 7/53 [==>...........................] - ETA: 5:36 - loss: 0.1362 - acc: 0.9443\u001b[0m\n",
      "\u001b[34m 8/53 [===>..........................] - ETA: 5:26 - loss: 0.1383 - acc: 0.9425\u001b[0m\n",
      "\u001b[34m 9/53 [====>.........................] - ETA: 5:18 - loss: 0.1352 - acc: 0.9456\u001b[0m\n",
      "\u001b[34m10/53 [====>.........................] - ETA: 5:09 - loss: 0.1280 - acc: 0.9500\u001b[0m\n",
      "\u001b[34m11/53 [=====>........................] - ETA: 5:01 - loss: 0.1271 - acc: 0.9491\u001b[0m\n",
      "\u001b[34m12/53 [=====>........................] - ETA: 4:53 - loss: 0.1334 - acc: 0.9450\u001b[0m\n",
      "\u001b[34m13/53 [======>.......................] - ETA: 4:45 - loss: 0.1334 - acc: 0.9454\u001b[0m\n",
      "\u001b[34m14/53 [======>.......................] - ETA: 4:37 - loss: 0.1350 - acc: 0.9457\u001b[0m\n",
      "\u001b[34m15/53 [=======>......................] - ETA: 4:30 - loss: 0.1385 - acc: 0.9447\u001b[0m\n",
      "\u001b[34m16/53 [========>.....................] - ETA: 4:22 - loss: 0.1382 - acc: 0.9456\u001b[0m\n",
      "\u001b[34m17/53 [========>.....................] - ETA: 4:15 - loss: 0.1408 - acc: 0.9441\u001b[0m\n",
      "\u001b[34m18/53 [=========>....................] - ETA: 4:08 - loss: 0.1433 - acc: 0.9428\u001b[0m\n",
      "\u001b[34m19/53 [=========>....................] - ETA: 4:00 - loss: 0.1425 - acc: 0.9421\u001b[0m\n",
      "\u001b[34m20/53 [==========>...................] - ETA: 3:53 - loss: 0.1426 - acc: 0.9425\u001b[0m\n",
      "\u001b[34m21/53 [==========>...................] - ETA: 3:46 - loss: 0.1420 - acc: 0.9433\u001b[0m\n",
      "\u001b[34m22/53 [===========>..................] - ETA: 3:38 - loss: 0.1456 - acc: 0.9418\u001b[0m\n",
      "\u001b[34m23/53 [============>.................] - ETA: 3:31 - loss: 0.1439 - acc: 0.9422\u001b[0m\n",
      "\u001b[34m24/53 [============>.................] - ETA: 3:24 - loss: 0.1419 - acc: 0.9433\u001b[0m\n",
      "\u001b[34m25/53 [=============>................] - ETA: 3:16 - loss: 0.1399 - acc: 0.9440\u001b[0m\n",
      "\u001b[34m26/53 [=============>................] - ETA: 3:09 - loss: 0.1407 - acc: 0.9438\u001b[0m\n",
      "\u001b[34m27/53 [==============>...............] - ETA: 3:02 - loss: 0.1413 - acc: 0.9433\u001b[0m\n",
      "\u001b[34m28/53 [==============>...............] - ETA: 2:55 - loss: 0.1421 - acc: 0.9425\u001b[0m\n",
      "\u001b[34m29/53 [===============>..............] - ETA: 2:48 - loss: 0.1420 - acc: 0.9421\u001b[0m\n",
      "\u001b[34m30/53 [===============>..............] - ETA: 2:41 - loss: 0.1430 - acc: 0.9413\u001b[0m\n",
      "\u001b[34m31/53 [================>.............] - ETA: 2:33 - loss: 0.1418 - acc: 0.9419\u001b[0m\n",
      "\u001b[34m32/53 [=================>............] - ETA: 2:26 - loss: 0.1407 - acc: 0.9428\u001b[0m\n",
      "\u001b[34m33/53 [=================>............] - ETA: 2:19 - loss: 0.1404 - acc: 0.9427\u001b[0m\n",
      "\u001b[34m34/53 [==================>...........] - ETA: 2:12 - loss: 0.1394 - acc: 0.9429\u001b[0m\n",
      "\u001b[34m35/53 [==================>...........] - ETA: 2:05 - loss: 0.1390 - acc: 0.9431\u001b[0m\n",
      "\u001b[34m36/53 [===================>..........] - ETA: 1:58 - loss: 0.1411 - acc: 0.9428\u001b[0m\n",
      "\u001b[34m37/53 [===================>..........] - ETA: 1:51 - loss: 0.1426 - acc: 0.9422\u001b[0m\n",
      "\u001b[34m38/53 [====================>.........] - ETA: 1:44 - loss: 0.1425 - acc: 0.9426\u001b[0m\n",
      "\u001b[34m39/53 [=====================>........] - ETA: 1:37 - loss: 0.1418 - acc: 0.9431\u001b[0m\n",
      "\u001b[34m40/53 [=====================>........] - ETA: 1:30 - loss: 0.1405 - acc: 0.9438\u001b[0m\n",
      "\u001b[34m41/53 [======================>.......] - ETA: 1:23 - loss: 0.1392 - acc: 0.9444\u001b[0m\n",
      "\u001b[34m42/53 [======================>.......] - ETA: 1:16 - loss: 0.1383 - acc: 0.9448\u001b[0m\n",
      "\u001b[34m43/53 [=======================>......] - ETA: 1:09 - loss: 0.1380 - acc: 0.9447\u001b[0m\n",
      "\u001b[34m44/53 [=======================>......] - ETA: 1:02 - loss: 0.1383 - acc: 0.9441\u001b[0m\n",
      "\u001b[34m45/53 [========================>.....] - ETA: 55s - loss: 0.1368 - acc: 0.9444 \u001b[0m\n",
      "\u001b[34m46/53 [=========================>....] - ETA: 48s - loss: 0.1363 - acc: 0.9446\u001b[0m\n",
      "\u001b[34m47/53 [=========================>....] - ETA: 41s - loss: 0.1385 - acc: 0.9434\u001b[0m\n",
      "\u001b[34m48/53 [==========================>...] - ETA: 34s - loss: 0.1380 - acc: 0.9433\u001b[0m\n",
      "\u001b[34m49/53 [==========================>...] - ETA: 27s - loss: 0.1369 - acc: 0.9437\u001b[0m\n",
      "\u001b[34m50/53 [===========================>..] - ETA: 20s - loss: 0.1363 - acc: 0.9440\u001b[0m\n",
      "\u001b[34m51/53 [===========================>..] - ETA: 13s - loss: 0.1349 - acc: 0.9449\u001b[0m\n",
      "\u001b[34m52/53 [============================>.] - ETA: 6s - loss: 0.1341 - acc: 0.9454 \u001b[0m\n",
      "\u001b[34m53/53 [==============================] - 364s 7s/step - loss: 0.1333 - acc: 0.9452 - val_loss: 2.9530 - val_acc: 0.5000\u001b[0m\n",
      "\u001b[34mEpoch 3/5\u001b[0m\n",
      "\u001b[34m 1/53 [..............................] - ETA: 6:01 - loss: 0.1579 - acc: 0.9400\u001b[0m\n",
      "\u001b[34m 2/53 [>.............................] - ETA: 5:53 - loss: 0.1347 - acc: 0.9550\u001b[0m\n",
      "\u001b[34m 3/53 [>.............................] - ETA: 5:49 - loss: 0.1172 - acc: 0.9667\u001b[0m\n",
      "\u001b[34m 4/53 [=>............................] - ETA: 5:41 - loss: 0.1199 - acc: 0.9600\u001b[0m\n",
      "\u001b[34m 5/53 [=>............................] - ETA: 5:34 - loss: 0.1347 - acc: 0.9540\u001b[0m\n",
      "\u001b[34m 6/53 [==>...........................] - ETA: 5:27 - loss: 0.1319 - acc: 0.9567\u001b[0m\n",
      "\u001b[34m 7/53 [==>...........................] - ETA: 5:20 - loss: 0.1224 - acc: 0.9586\u001b[0m\n",
      "\u001b[34m 8/53 [===>..........................] - ETA: 5:13 - loss: 0.1171 - acc: 0.9613\u001b[0m\n",
      "\u001b[34m 9/53 [====>.........................] - ETA: 5:06 - loss: 0.1228 - acc: 0.9567\u001b[0m\n",
      "\u001b[34m10/53 [====>.........................] - ETA: 4:59 - loss: 0.1182 - acc: 0.9590\u001b[0m\n",
      "\u001b[34m11/53 [=====>........................] - ETA: 4:52 - loss: 0.1159 - acc: 0.9600\u001b[0m\n",
      "\u001b[34m12/53 [=====>........................] - ETA: 4:45 - loss: 0.1127 - acc: 0.9617\u001b[0m\n",
      "\u001b[34m13/53 [======>.......................] - ETA: 4:37 - loss: 0.1127 - acc: 0.9623\u001b[0m\n",
      "\u001b[34m14/53 [======>.......................] - ETA: 4:30 - loss: 0.1105 - acc: 0.9629\u001b[0m\n",
      "\u001b[34m15/53 [=======>......................] - ETA: 4:22 - loss: 0.1141 - acc: 0.9620\u001b[0m\n",
      "\u001b[34m16/53 [========>.....................] - ETA: 4:15 - loss: 0.1163 - acc: 0.9606\u001b[0m\n",
      "\u001b[34m17/53 [========>.....................] - ETA: 4:08 - loss: 0.1140 - acc: 0.9618\u001b[0m\n",
      "\u001b[34m18/53 [=========>....................] - ETA: 4:01 - loss: 0.1150 - acc: 0.9611\u001b[0m\n",
      "\u001b[34m19/53 [=========>....................] - ETA: 3:54 - loss: 0.1151 - acc: 0.9611\u001b[0m\n",
      "\u001b[34m20/53 [==========>...................] - ETA: 3:47 - loss: 0.1141 - acc: 0.9615\u001b[0m\n",
      "\u001b[34m21/53 [==========>...................] - ETA: 3:40 - loss: 0.1143 - acc: 0.9619\u001b[0m\n",
      "\u001b[34m22/53 [===========>..................] - ETA: 3:33 - loss: 0.1112 - acc: 0.9636\u001b[0m\n",
      "\u001b[34m23/53 [============>.................] - ETA: 3:26 - loss: 0.1110 - acc: 0.9643\u001b[0m\n",
      "\u001b[34m24/53 [============>.................] - ETA: 3:19 - loss: 0.1107 - acc: 0.9633\u001b[0m\n",
      "\u001b[34m25/53 [=============>................] - ETA: 3:12 - loss: 0.1115 - acc: 0.9636\u001b[0m\n",
      "\u001b[34m26/53 [=============>................] - ETA: 3:06 - loss: 0.1124 - acc: 0.9635\u001b[0m\n",
      "\u001b[34m27/53 [==============>...............] - ETA: 2:59 - loss: 0.1132 - acc: 0.9637\u001b[0m\n",
      "\u001b[34m28/53 [==============>...............] - ETA: 2:52 - loss: 0.1125 - acc: 0.9639\u001b[0m\n",
      "\u001b[34m29/53 [===============>..............] - ETA: 2:45 - loss: 0.1113 - acc: 0.9641\u001b[0m\n",
      "\u001b[34m30/53 [===============>..............] - ETA: 2:38 - loss: 0.1097 - acc: 0.9647\u001b[0m\n",
      "\u001b[34m31/53 [================>.............] - ETA: 2:31 - loss: 0.1094 - acc: 0.9648\u001b[0m\n",
      "\u001b[34m32/53 [=================>............] - ETA: 2:24 - loss: 0.1090 - acc: 0.9653\u001b[0m\n",
      "\u001b[34m33/53 [=================>............] - ETA: 2:18 - loss: 0.1091 - acc: 0.9648\u001b[0m\n",
      "\u001b[34m34/53 [==================>...........] - ETA: 2:11 - loss: 0.1097 - acc: 0.9644\u001b[0m\n",
      "\u001b[34m35/53 [==================>...........] - ETA: 2:04 - loss: 0.1100 - acc: 0.9643\u001b[0m\n",
      "\u001b[34m36/53 [===================>..........] - ETA: 1:57 - loss: 0.1093 - acc: 0.9644\u001b[0m\n",
      "\u001b[34m37/53 [===================>..........] - ETA: 1:50 - loss: 0.1090 - acc: 0.9643\u001b[0m\n",
      "\u001b[34m38/53 [====================>.........] - ETA: 1:43 - loss: 0.1077 - acc: 0.9647\u001b[0m\n",
      "\u001b[34m39/53 [=====================>........] - ETA: 1:36 - loss: 0.1065 - acc: 0.9654\u001b[0m\n",
      "\u001b[34m40/53 [=====================>........] - ETA: 1:29 - loss: 0.1050 - acc: 0.9660\u001b[0m\n",
      "\u001b[34m41/53 [======================>.......] - ETA: 1:22 - loss: 0.1041 - acc: 0.9666\u001b[0m\n",
      "\u001b[34m42/53 [======================>.......] - ETA: 1:15 - loss: 0.1044 - acc: 0.9664\u001b[0m\n",
      "\u001b[34m43/53 [=======================>......] - ETA: 1:08 - loss: 0.1045 - acc: 0.9663\u001b[0m\n",
      "\u001b[34m44/53 [=======================>......] - ETA: 1:02 - loss: 0.1047 - acc: 0.9664\u001b[0m\n",
      "\u001b[34m45/53 [========================>.....] - ETA: 55s - loss: 0.1050 - acc: 0.9662 \u001b[0m\n",
      "\u001b[34m46/53 [=========================>....] - ETA: 48s - loss: 0.1057 - acc: 0.9659\u001b[0m\n",
      "\u001b[34m47/53 [=========================>....] - ETA: 41s - loss: 0.1063 - acc: 0.9651\u001b[0m\n",
      "\u001b[34m48/53 [==========================>...] - ETA: 34s - loss: 0.1053 - acc: 0.9652\u001b[0m\n",
      "\u001b[34m49/53 [==========================>...] - ETA: 27s - loss: 0.1052 - acc: 0.9653\u001b[0m\n",
      "\u001b[34m50/53 [===========================>..] - ETA: 20s - loss: 0.1043 - acc: 0.9658\u001b[0m\n",
      "\u001b[34m51/53 [===========================>..] - ETA: 13s - loss: 0.1041 - acc: 0.9657\u001b[0m\n",
      "\u001b[34m52/53 [============================>.] - ETA: 6s - loss: 0.1036 - acc: 0.9654 \u001b[0m\n",
      "\u001b[34m53/53 [==============================] - 362s 7s/step - loss: 0.1047 - acc: 0.9649 - val_loss: 3.0253 - val_acc: 0.5000\u001b[0m\n",
      "\u001b[34mEpoch 4/5\u001b[0m\n",
      "\u001b[34m 1/53 [..............................] - ETA: 6:07 - loss: 0.0952 - acc: 0.9600\u001b[0m\n",
      "\u001b[34m 2/53 [>.............................] - ETA: 5:54 - loss: 0.1196 - acc: 0.9550\u001b[0m\n",
      "\u001b[34m 3/53 [>.............................] - ETA: 5:48 - loss: 0.1412 - acc: 0.9467\u001b[0m\n",
      "\u001b[34m 4/53 [=>............................] - ETA: 5:40 - loss: 0.1212 - acc: 0.9575\u001b[0m\n",
      "\u001b[34m 5/53 [=>............................] - ETA: 5:31 - loss: 0.1193 - acc: 0.9580\u001b[0m\n",
      "\u001b[34m 6/53 [==>...........................] - ETA: 5:22 - loss: 0.1122 - acc: 0.9600\u001b[0m\n",
      "\u001b[34m 7/53 [==>...........................] - ETA: 5:15 - loss: 0.1132 - acc: 0.9614\u001b[0m\n",
      "\u001b[34m 8/53 [===>..........................] - ETA: 5:08 - loss: 0.1110 - acc: 0.9600\u001b[0m\n",
      "\u001b[34m 9/53 [====>.........................] - ETA: 5:01 - loss: 0.1063 - acc: 0.9633\u001b[0m\n",
      "\u001b[34m10/53 [====>.........................] - ETA: 4:54 - loss: 0.1042 - acc: 0.9630\u001b[0m\n",
      "\u001b[34m11/53 [=====>........................] - ETA: 4:47 - loss: 0.1010 - acc: 0.9636\u001b[0m\n",
      "\u001b[34m12/53 [=====>........................] - ETA: 4:42 - loss: 0.1002 - acc: 0.9642\u001b[0m\n",
      "\u001b[34m13/53 [======>.......................] - ETA: 4:36 - loss: 0.1037 - acc: 0.9608\u001b[0m\n",
      "\u001b[34m14/53 [======>.......................] - ETA: 4:28 - loss: 0.1021 - acc: 0.9621\u001b[0m\n",
      "\u001b[34m15/53 [=======>......................] - ETA: 4:22 - loss: 0.0999 - acc: 0.9633\u001b[0m\n",
      "\u001b[34m16/53 [========>.....................] - ETA: 4:15 - loss: 0.0968 - acc: 0.9650\u001b[0m\n",
      "\u001b[34m17/53 [========>.....................] - ETA: 4:08 - loss: 0.0960 - acc: 0.9653\u001b[0m\n",
      "\u001b[34m18/53 [=========>....................] - ETA: 4:01 - loss: 0.0951 - acc: 0.9656\u001b[0m\n",
      "\u001b[34m19/53 [=========>....................] - ETA: 3:54 - loss: 0.0929 - acc: 0.9663\u001b[0m\n",
      "\u001b[34m20/53 [==========>...................] - ETA: 3:48 - loss: 0.0932 - acc: 0.9670\u001b[0m\n",
      "\u001b[34m21/53 [==========>...................] - ETA: 3:41 - loss: 0.0919 - acc: 0.9676\u001b[0m\n",
      "\u001b[34m22/53 [===========>..................] - ETA: 3:34 - loss: 0.0917 - acc: 0.9668\u001b[0m\n",
      "\u001b[34m23/53 [============>.................] - ETA: 3:27 - loss: 0.0920 - acc: 0.9665\u001b[0m\n",
      "\u001b[34m24/53 [============>.................] - ETA: 3:20 - loss: 0.0906 - acc: 0.9675\u001b[0m\n",
      "\u001b[34m25/53 [=============>................] - ETA: 3:14 - loss: 0.0896 - acc: 0.9672\u001b[0m\n",
      "\u001b[34m26/53 [=============>................] - ETA: 3:07 - loss: 0.0880 - acc: 0.9681\u001b[0m\n",
      "\u001b[34m27/53 [==============>...............] - ETA: 3:00 - loss: 0.0898 - acc: 0.9674\u001b[0m\n",
      "\u001b[34m28/53 [==============>...............] - ETA: 2:53 - loss: 0.0894 - acc: 0.9671\u001b[0m\n",
      "\u001b[34m29/53 [===============>..............] - ETA: 2:46 - loss: 0.0885 - acc: 0.9676\u001b[0m\n",
      "\u001b[34m30/53 [===============>..............] - ETA: 2:39 - loss: 0.0893 - acc: 0.9673\u001b[0m\n",
      "\u001b[34m31/53 [================>.............] - ETA: 2:32 - loss: 0.0888 - acc: 0.9677\u001b[0m\n",
      "\u001b[34m32/53 [=================>............] - ETA: 2:25 - loss: 0.0890 - acc: 0.9675\u001b[0m\n",
      "\u001b[34m33/53 [=================>............] - ETA: 2:18 - loss: 0.0896 - acc: 0.9676\u001b[0m\n",
      "\u001b[34m34/53 [==================>...........] - ETA: 2:11 - loss: 0.0897 - acc: 0.9671\u001b[0m\n",
      "\u001b[34m35/53 [==================>...........] - ETA: 2:04 - loss: 0.0890 - acc: 0.9677\u001b[0m\n",
      "\u001b[34m36/53 [===================>..........] - ETA: 1:57 - loss: 0.0883 - acc: 0.9683\u001b[0m\n",
      "\u001b[34m37/53 [===================>..........] - ETA: 1:50 - loss: 0.0876 - acc: 0.9684\u001b[0m\n",
      "\u001b[34m38/53 [====================>.........] - ETA: 1:44 - loss: 0.0887 - acc: 0.9682\u001b[0m\n",
      "\u001b[34m39/53 [=====================>........] - ETA: 1:37 - loss: 0.0881 - acc: 0.9687\u001b[0m\n",
      "\u001b[34m40/53 [=====================>........] - ETA: 1:30 - loss: 0.0894 - acc: 0.9683\u001b[0m\n",
      "\u001b[34m41/53 [======================>.......] - ETA: 1:23 - loss: 0.0896 - acc: 0.9683\u001b[0m\n",
      "\u001b[34m42/53 [======================>.......] - ETA: 1:16 - loss: 0.0902 - acc: 0.9679\u001b[0m\n",
      "\u001b[34m43/53 [=======================>......] - ETA: 1:09 - loss: 0.0898 - acc: 0.9679\u001b[0m\n",
      "\u001b[34m44/53 [=======================>......] - ETA: 1:02 - loss: 0.0891 - acc: 0.9684\u001b[0m\n",
      "\u001b[34m45/53 [========================>.....] - ETA: 55s - loss: 0.0900 - acc: 0.9684 \u001b[0m\n",
      "\u001b[34m46/53 [=========================>....] - ETA: 48s - loss: 0.0900 - acc: 0.9685\u001b[0m\n",
      "\u001b[34m47/53 [=========================>....] - ETA: 41s - loss: 0.0898 - acc: 0.9685\u001b[0m\n",
      "\u001b[34m48/53 [==========================>...] - ETA: 34s - loss: 0.0892 - acc: 0.9688\u001b[0m\n",
      "\u001b[34m49/53 [==========================>...] - ETA: 27s - loss: 0.0897 - acc: 0.9686\u001b[0m\n",
      "\u001b[34m50/53 [===========================>..] - ETA: 20s - loss: 0.0897 - acc: 0.9686\u001b[0m\n",
      "\u001b[34m51/53 [===========================>..] - ETA: 13s - loss: 0.0898 - acc: 0.9684\u001b[0m\n",
      "\u001b[34m52/53 [============================>.] - ETA: 6s - loss: 0.0900 - acc: 0.9683 \u001b[0m\n",
      "\u001b[34m53/53 [==============================] - 363s 7s/step - loss: 0.0892 - acc: 0.9689 - val_loss: 3.6643 - val_acc: 0.5000\u001b[0m\n",
      "\u001b[34mEpoch 5/5\u001b[0m\n",
      "\u001b[34m 1/53 [..............................] - ETA: 6:07 - loss: 0.0939 - acc: 0.9700\u001b[0m\n",
      "\u001b[34m 2/53 [>.............................] - ETA: 5:54 - loss: 0.0726 - acc: 0.9800\u001b[0m\n",
      "\u001b[34m 3/53 [>.............................] - ETA: 5:50 - loss: 0.0704 - acc: 0.9833\u001b[0m\n",
      "\u001b[34m 4/53 [=>............................] - ETA: 5:42 - loss: 0.0735 - acc: 0.9750\u001b[0m\n",
      "\u001b[34m 5/53 [=>............................] - ETA: 5:34 - loss: 0.0667 - acc: 0.9800\u001b[0m\n",
      "\u001b[34m 6/53 [==>...........................] - ETA: 5:28 - loss: 0.0675 - acc: 0.9783\u001b[0m\n",
      "\u001b[34m 7/53 [==>...........................] - ETA: 5:22 - loss: 0.0677 - acc: 0.9771\u001b[0m\n",
      "\u001b[34m 8/53 [===>..........................] - ETA: 5:14 - loss: 0.0668 - acc: 0.9775\u001b[0m\n",
      "\u001b[34m 9/53 [====>.........................] - ETA: 5:06 - loss: 0.0665 - acc: 0.9778\u001b[0m\n",
      "\u001b[34m10/53 [====>.........................] - ETA: 4:59 - loss: 0.0638 - acc: 0.9780\u001b[0m\n",
      "\u001b[34m11/53 [=====>........................] - ETA: 4:52 - loss: 0.0654 - acc: 0.9791\u001b[0m\n",
      "\u001b[34m12/53 [=====>........................] - ETA: 4:45 - loss: 0.0649 - acc: 0.9783\u001b[0m\n",
      "\u001b[34m13/53 [======>.......................] - ETA: 4:38 - loss: 0.0672 - acc: 0.9777\u001b[0m\n",
      "\u001b[34m14/53 [======>.......................] - ETA: 4:31 - loss: 0.0696 - acc: 0.9764\u001b[0m\n",
      "\u001b[34m15/53 [=======>......................] - ETA: 4:24 - loss: 0.0724 - acc: 0.9760\u001b[0m\n",
      "\u001b[34m16/53 [========>.....................] - ETA: 4:17 - loss: 0.0742 - acc: 0.9756\u001b[0m\n",
      "\u001b[34m17/53 [========>.....................] - ETA: 4:10 - loss: 0.0764 - acc: 0.9735\u001b[0m\n",
      "\u001b[34m18/53 [=========>....................] - ETA: 4:04 - loss: 0.0760 - acc: 0.9728\u001b[0m\n",
      "\u001b[34m19/53 [=========>....................] - ETA: 3:56 - loss: 0.0774 - acc: 0.9721\u001b[0m\n",
      "\u001b[34m20/53 [==========>...................] - ETA: 3:49 - loss: 0.0782 - acc: 0.9720\u001b[0m\n",
      "\u001b[34m21/53 [==========>...................] - ETA: 3:43 - loss: 0.0786 - acc: 0.9710\u001b[0m\n",
      "\u001b[34m22/53 [===========>..................] - ETA: 3:35 - loss: 0.0773 - acc: 0.9714\u001b[0m\n",
      "\u001b[34m23/53 [============>.................] - ETA: 3:28 - loss: 0.0791 - acc: 0.9704\u001b[0m\n",
      "\u001b[34m24/53 [============>.................] - ETA: 3:21 - loss: 0.0786 - acc: 0.9708\u001b[0m\n",
      "\u001b[34m25/53 [=============>................] - ETA: 3:15 - loss: 0.0773 - acc: 0.9716\u001b[0m\n",
      "\u001b[34m26/53 [=============>................] - ETA: 3:08 - loss: 0.0776 - acc: 0.9719\u001b[0m\n",
      "\u001b[34m27/53 [==============>...............] - ETA: 3:01 - loss: 0.0785 - acc: 0.9719\u001b[0m\n",
      "\u001b[34m28/53 [==============>...............] - ETA: 2:54 - loss: 0.0812 - acc: 0.9704\u001b[0m\n",
      "\u001b[34m29/53 [===============>..............] - ETA: 2:47 - loss: 0.0805 - acc: 0.9707\u001b[0m\n",
      "\u001b[34m30/53 [===============>..............] - ETA: 2:40 - loss: 0.0813 - acc: 0.9700\u001b[0m\n",
      "\u001b[34m31/53 [================>.............] - ETA: 2:33 - loss: 0.0820 - acc: 0.9697\u001b[0m\n",
      "\u001b[34m32/53 [=================>............] - ETA: 2:26 - loss: 0.0810 - acc: 0.9706\u001b[0m\n",
      "\u001b[34m33/53 [=================>............] - ETA: 2:19 - loss: 0.0803 - acc: 0.9712\u001b[0m\n",
      "\u001b[34m34/53 [==================>...........] - ETA: 2:12 - loss: 0.0798 - acc: 0.9715\u001b[0m\n",
      "\u001b[34m35/53 [==================>...........] - ETA: 2:05 - loss: 0.0813 - acc: 0.9709\u001b[0m\n",
      "\u001b[34m36/53 [===================>..........] - ETA: 1:58 - loss: 0.0818 - acc: 0.9706\u001b[0m\n",
      "\u001b[34m37/53 [===================>..........] - ETA: 1:51 - loss: 0.0814 - acc: 0.9708\u001b[0m\n",
      "\u001b[34m38/53 [====================>.........] - ETA: 1:44 - loss: 0.0816 - acc: 0.9705\u001b[0m\n",
      "\u001b[34m39/53 [=====================>........] - ETA: 1:37 - loss: 0.0815 - acc: 0.9705\u001b[0m\n",
      "\u001b[34m40/53 [=====================>........] - ETA: 1:30 - loss: 0.0816 - acc: 0.9705\u001b[0m\n",
      "\u001b[34m41/53 [======================>.......] - ETA: 1:23 - loss: 0.0805 - acc: 0.9712\u001b[0m\n",
      "\u001b[34m42/53 [======================>.......] - ETA: 1:16 - loss: 0.0805 - acc: 0.9710\u001b[0m\n",
      "\u001b[34m43/53 [=======================>......] - ETA: 1:09 - loss: 0.0803 - acc: 0.9709\u001b[0m\n",
      "\u001b[34m44/53 [=======================>......] - ETA: 1:02 - loss: 0.0793 - acc: 0.9714\u001b[0m\n",
      "\u001b[34m45/53 [========================>.....] - ETA: 55s - loss: 0.0794 - acc: 0.9711 \u001b[0m\n",
      "\u001b[34m46/53 [=========================>....] - ETA: 48s - loss: 0.0794 - acc: 0.9711\u001b[0m\n",
      "\u001b[34m47/53 [=========================>....] - ETA: 41s - loss: 0.0790 - acc: 0.9713\u001b[0m\n",
      "\u001b[34m48/53 [==========================>...] - ETA: 34s - loss: 0.0788 - acc: 0.9713\u001b[0m\n",
      "\u001b[34m49/53 [==========================>...] - ETA: 27s - loss: 0.0784 - acc: 0.9716\u001b[0m\n",
      "\u001b[34m50/53 [===========================>..] - ETA: 20s - loss: 0.0791 - acc: 0.9710\u001b[0m\n",
      "\u001b[34m51/53 [===========================>..] - ETA: 13s - loss: 0.0794 - acc: 0.9710\u001b[0m\n",
      "\u001b[34m52/53 [============================>.] - ETA: 6s - loss: 0.0797 - acc: 0.9710 \u001b[0m\n",
      "\u001b[34m53/53 [==============================] - 363s 7s/step - loss: 0.0785 - acc: 0.9715 - val_loss: 3.3370 - val_acc: 0.5000\u001b[0m\n",
      "\u001b[34m('Validation loss    :', 3.3369948863983154)\u001b[0m\n",
      "\u001b[34m('Validation accuracy:', 0.5)\u001b[0m\n",
      "\u001b[34mW0609 16:21:53.105734 140150207923968 deprecation.py:323] From model.py:135: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\u001b[0m\n",
      "\u001b[34mW0609 16:21:53.105909 140150207923968 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\u001b[0m\n",
      "\n",
      "2020-06-09 16:22:01 Uploading - Uploading generated training model\n",
      "2020-06-09 16:22:18 Completed - Training job completed\n",
      "Training seconds: 1952\n",
      "Billable seconds: 617\n",
      "Managed Spot Training savings: 68.4%\n",
      "Deploying ...\n",
      "-------------!Predictor endpoint name : tensorflow-training-2020-06-09-15-47-23-605\n",
      
     ]
    },
    "source": [
    "estimator = TensorFlow(\n",
    "  entry_point=\"model.py\",             # Your entry script\n",
    "  role=role,\n",
    "  framework_version=\"1.14.0\",               # TensorFlow's version\n",
    "  hyperparameters=hyperparameters,\n",
    "  training_steps=100,\n",
    "  evaluation_steps=100,\n",
    "  train_instance_count=1,                   # \"The number of GPUs instances to use\"\n",
    "  train_instance_type=train_instance_type,\n",
    "  train_use_spot_instances=train_use_spot_instances,  \n",
    "  train_max_run=train_max_run,\n",
    "  train_max_wait=train_max_wait\n",
    "    \n",
    ")\n",
    "\n",
    "print(\"Training ...\")\n",
    "estimator.fit({'training': train_input_path, 'validation': validation_input_path})\n",
    "\n",
    "print(\"Deploying ...\")\n",
    "predictor = estimator.deploy(initial_instance_count=1, instance_type=deploy_instance_type)\n",
    "\n",
    "print(\"Predictor endpoint name : %s\" % predictor.endpoint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
